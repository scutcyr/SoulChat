# [çµå¿ƒï¼ˆSoulChatï¼‰]((https://github.com/scutcyr/SoulChat))
<p align="center">
    <img src="./figure/soulchat_poster.png" width=900px/>
</p>
<p align="center">
    <a href="./LICENSE"><img src="https://img.shields.io/badge/license-Apache%202-red.svg"></a>
    <a href="support os"><img src="https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg"></a>
    <a href=""><img src="https://img.shields.io/badge/python-3.8+-aff.svg"></a>
    <a href="https://github.com/scutcyr/SoulChat/graphs/contributors"><img src="https://img.shields.io/github/contributors/scutcyr/SoulChat?color=9ea"></a>
    <a href="https://github.com/scutcyr/SoulChat/commits"><img src="https://img.shields.io/github/commit-activity/m/scutcyr/SoulChat?color=3af"></a>
    <a href="https://github.com/scutcyr/SoulChat/issues"><img src="https://img.shields.io/github/issues/scutcyr/SoulChat?color=9cc"></a>
    <a href="https://github.com/scutcyr/SoulChat/stargazers"><img src="https://img.shields.io/github/stars/scutcyr/SoulChat?color=ccf"></a>
</p>

åŸºäºä¸»åŠ¨å¥åº·çš„ä¸»åŠ¨æ€§ã€é¢„é˜²æ€§ã€ç²¾ç¡®æ€§ã€ä¸ªæ€§åŒ–ã€å…±å»ºå…±äº«ã€è‡ªå¾‹æ€§å…­å¤§ç‰¹å¾ï¼Œåå—ç†å·¥å¤§å­¦æœªæ¥æŠ€æœ¯å­¦é™¢-å¹¿ä¸œçœæ•°å­—å­ªç”Ÿäººé‡ç‚¹å®éªŒå®¤å¼€æºäº†ä¸­æ–‡é¢†åŸŸç”Ÿæ´»ç©ºé—´ä¸»åŠ¨å¥åº·å¤§æ¨¡å‹åŸºåº§ProactiveHealthGPTï¼ŒåŒ…æ‹¬ï¼š
* ç»è¿‡åƒä¸‡è§„æ¨¡ä¸­æ–‡å¥åº·å¯¹è¯æ•°æ®æŒ‡ä»¤å¾®è°ƒçš„[ç”Ÿæ´»ç©ºé—´å¥åº·å¤§æ¨¡å‹æ‰é¹Šï¼ˆBianQueï¼‰](https://github.com/scutcyr/BianQue)    
* ç»è¿‡ç™¾ä¸‡è§„æ¨¡å¿ƒç†å’¨è¯¢é¢†åŸŸä¸­æ–‡é•¿æ–‡æœ¬æŒ‡ä»¤ä¸å¤šè½®å…±æƒ…å¯¹è¯æ•°æ®è”åˆæŒ‡ä»¤å¾®è°ƒçš„[å¿ƒç†å¥åº·å¤§æ¨¡å‹çµå¿ƒï¼ˆSoulChatï¼‰](https://github.com/scutcyr/SoulChat)   

æˆ‘ä»¬æœŸæœ›ï¼Œ**ç”Ÿæ´»ç©ºé—´ä¸»åŠ¨å¥åº·å¤§æ¨¡å‹åŸºåº§ProactiveHealthGPT** å¯ä»¥å¸®åŠ©å­¦æœ¯ç•ŒåŠ é€Ÿå¤§æ¨¡å‹åœ¨æ…¢æ€§ç—…ã€å¿ƒç†å’¨è¯¢ç­‰ä¸»åŠ¨å¥åº·é¢†åŸŸçš„ç ”ç©¶ä¸åº”ç”¨ã€‚æœ¬é¡¹ç›®ä¸º **å¿ƒç†å¥åº·å¤§æ¨¡å‹çµå¿ƒï¼ˆSoulChatï¼‰** ã€‚


## æœ€è¿‘æ›´æ–°
- ğŸ‘ğŸ»  2023.12.09ï¼šæˆ‘ä»¬çš„æ•°æ®é›†å³å°†å‘å¸ƒï¼ï¼ï¼
- ğŸ‘ğŸ»  2023.12.07ï¼šæˆ‘ä»¬çš„è®ºæ–‡ï¼Œæ”¶å½•åœ¨Findings of EMNLP 2023ï¼Œè¯¦è§[SoulChat: Improving LLMsâ€™ Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations](https://aclanthology.org/2023.findings-emnlp.83/)
- ğŸ‘ğŸ»  2023.07.07: å¿ƒç†å¥åº·å¤§æ¨¡å‹çµå¿ƒï¼ˆSoulChatï¼‰åœ¨çº¿å†…æµ‹ç‰ˆæœ¬å¯ç”¨ï¼Œæ¬¢è¿ç‚¹å‡»é“¾æ¥ä½¿ç”¨ï¼š[çµå¿ƒå†…æµ‹ç‰ˆ](https://soulchat.iai007.cloud/)ã€‚
- ğŸ‘ğŸ»  2023.06.24: æœ¬é¡¹ç›®è¢«æ”¶å½•åˆ°[ä¸­å›½å¤§æ¨¡å‹åˆ—è¡¨](https://github.com/wgwang/LLMs-In-China)ï¼Œä¸ºå›½å†…é¦–ä¸ªå¼€æºçš„å…·å¤‡å…±æƒ…ä¸å€¾å¬èƒ½åŠ›çš„å¿ƒç†é¢†åŸŸå¤§æ¨¡å‹ã€‚
- ğŸ‘ğŸ»  2023.06.06: æ‰é¹Š-2.0æ¨¡å‹å¼€æºï¼Œè¯¦æƒ…è§[BianQue-2.0](https://huggingface.co/scutcyr/BianQue-2)ã€‚
- ğŸ‘ğŸ»  2023.06.06: å…·å¤‡å…±æƒ…ä¸å€¾å¬èƒ½åŠ›çš„çµå¿ƒå¥åº·å¤§æ¨¡å‹SoulChatå‘å¸ƒï¼Œè¯¦æƒ…è§ï¼š[çµå¿ƒå¥åº·å¤§æ¨¡å‹SoulChatï¼šé€šè¿‡é•¿æ–‡æœ¬å’¨è¯¢æŒ‡ä»¤ä¸å¤šè½®å…±æƒ…å¯¹è¯æ•°æ®é›†çš„æ··åˆå¾®è°ƒï¼Œæå‡å¤§æ¨¡å‹çš„â€œå…±æƒ…â€èƒ½åŠ› ](https://huggingface.co/scutcyr/SoulChat)ã€‚
- ğŸ‘ğŸ»  2023.04.22: åŸºäºæ‰é¹Š-1.0æ¨¡å‹çš„åŒ»ç–—é—®ç­”ç³»ç»ŸDemoï¼Œè¯¦æƒ…è®¿é—®ï¼š[https://huggingface.co/spaces/scutcyr/BianQue](https://huggingface.co/spaces/scutcyr/BianQue)
- ğŸ‘ğŸ»  2023.04.22: æ‰é¹Š-1.0ç‰ˆæœ¬æ¨¡å‹å‘å¸ƒï¼Œè¯¦æƒ…è§ï¼š[æ‰é¹Š-1.0ï¼šé€šè¿‡æ··åˆæŒ‡ä»¤å’Œå¤šè½®åŒ»ç”Ÿé—®è¯¢æ•°æ®é›†çš„å¾®è°ƒï¼Œæé«˜åŒ»ç–—èŠå¤©æ¨¡å‹çš„â€œé—®â€èƒ½åŠ›ï¼ˆBianQue-1.0: Improving the "Question" Ability of Medical Chat Model through finetuning with Hybrid Instructions and Multi-turn Doctor QA Datasetsï¼‰](https://huggingface.co/scutcyr/BianQue-1.0)


## ç®€ä»‹
   æˆ‘ä»¬è°ƒç ”äº†å½“å‰å¸¸è§çš„å¿ƒç†å’¨è¯¢å¹³å°ï¼Œå‘ç°ï¼Œç”¨æˆ·å¯»æ±‚åœ¨çº¿å¿ƒç†å¸®åŠ©æ—¶ï¼Œé€šå¸¸éœ€è¦è¿›è¡Œè¾ƒé•¿ç¯‡å¹…åœ°è¿›è¡Œè‡ªæˆ‘æè¿°ï¼Œç„¶åæä¾›å¸®åŠ©çš„å¿ƒç†å’¨è¯¢å¸ˆåŒæ ·åœ°æä¾›é•¿ç¯‡å¹…çš„å›å¤ï¼ˆè§[figure/single_turn.png](./figure/single_turn.png)ï¼‰ï¼Œç¼ºå¤±äº†ä¸€ä¸ªæ¸è¿›å¼çš„å€¾è¯‰è¿‡ç¨‹ã€‚ä½†æ˜¯ï¼Œåœ¨å®é™…çš„å¿ƒç†å’¨è¯¢è¿‡ç¨‹å½“ä¸­ï¼Œç”¨æˆ·å’Œå¿ƒç†å’¨è¯¢å¸ˆä¹‹é—´ä¼šå­˜åœ¨å¤šè½®æ¬¡çš„æ²Ÿé€šè¿‡ç¨‹ï¼Œåœ¨è¯¥è¿‡ç¨‹å½“ä¸­ï¼Œå¿ƒç†å’¨è¯¢å¸ˆä¼šå¼•å¯¼ç”¨æˆ·è¿›è¡Œå€¾è¯‰ï¼Œå¹¶ä¸”æä¾›å…±æƒ…ï¼Œä¾‹å¦‚ï¼šâ€œéå¸¸æ£’â€ã€â€œæˆ‘ç†è§£ä½ çš„æ„Ÿå—â€ã€â€œå½“ç„¶å¯ä»¥â€ç­‰ç­‰ï¼ˆè§ä¸‹å›¾ï¼‰ã€‚
<p align="center">
    <img src="./figure/multi_turn.png" width=900px/>
</p>

   è€ƒè™‘åˆ°å½“å‰ååˆ†æ¬ ç¼ºå¤šè½®å…±æƒ…å¯¹è¯æ•°æ®é›†ï¼Œæˆ‘ä»¬ä¸€æ–¹é¢ï¼Œæ„å»ºäº†è¶…è¿‡15ä¸‡è§„æ¨¡çš„ **å•è½®é•¿æ–‡æœ¬å¿ƒç†å’¨è¯¢æŒ‡ä»¤ä¸ç­”æ¡ˆï¼ˆSoulChatCorpus-single_turnï¼‰** ï¼Œå›ç­”æ•°é‡è¶…è¿‡50ä¸‡ï¼ˆæŒ‡ä»¤æ•°æ˜¯å½“å‰çš„å¸¸è§çš„å¿ƒç†å’¨è¯¢æ•°æ®é›† [PsyQA](https://github.com/thu-coai/PsyQA) çš„6.7å€ï¼‰ï¼Œå¹¶åˆ©ç”¨ChatGPTä¸GPT4ï¼Œç”Ÿæˆæ€»å…±çº¦100ä¸‡è½®æ¬¡çš„ **å¤šè½®å›ç­”æ•°æ®ï¼ˆSoulChatCorpus-multi_turnï¼‰** ã€‚ç‰¹åˆ«åœ°ï¼Œæˆ‘ä»¬åœ¨é¢„å®éªŒä¸­å‘ç°ï¼Œçº¯å•è½®é•¿æœ¬æ–‡é©±åŠ¨çš„å¿ƒç†å’¨è¯¢æ¨¡å‹ä¼šäº§ç”Ÿè®©ç”¨æˆ·æ„Ÿåˆ°åŒçƒ¦çš„æ–‡æœ¬é•¿åº¦ï¼Œè€Œä¸”ä¸å…·å¤‡å¼•å¯¼ç”¨æˆ·å€¾è¯‰çš„èƒ½åŠ›ï¼Œçº¯å¤šè½®å¿ƒç†å’¨è¯¢å¯¹è¯æ•°æ®é©±åŠ¨çš„å¿ƒç†å’¨è¯¢æ¨¡å‹åˆ™å¼±åŒ–äº†æ¨¡å‹çš„å»ºè®®èƒ½åŠ›ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬æ··åˆSoulChatCorpus-single_turnå’ŒSoulChatCorpus-multi_turnæ„é€ æˆè¶…è¿‡120ä¸‡ä¸ªæ ·æœ¬çš„ **å•è½®ä¸å¤šè½®æ··åˆçš„å…±æƒ…å¯¹è¯æ•°æ®é›†SoulChatCorpus** ã€‚æ‰€æœ‰æ•°æ®é‡‡ç”¨â€œç”¨æˆ·ï¼šxxx\nå¿ƒç†å’¨è¯¢å¸ˆï¼šxxx\nç”¨æˆ·ï¼šxxx\nå¿ƒç†å’¨è¯¢å¸ˆï¼šâ€çš„å½¢å¼ç»Ÿä¸€ä¸ºä¸€ç§æŒ‡ä»¤æ ¼å¼ã€‚

æˆ‘ä»¬é€‰æ‹©äº† [ChatGLM-6B](https://huggingface.co/THUDM/chatglm-6b) ä½œä¸ºåˆå§‹åŒ–æ¨¡å‹ï¼Œè¿›è¡Œäº†**å…¨é‡å‚æ•°çš„æŒ‡ä»¤å¾®è°ƒ**ï¼Œæ—¨åœ¨æå‡æ¨¡å‹çš„å…±æƒ…èƒ½åŠ›ã€å¼•å¯¼ç”¨æˆ·å€¾è¯‰èƒ½åŠ›ä»¥åŠæä¾›åˆç†å»ºè®®çš„èƒ½åŠ›ã€‚æ›´å¤šè®­ç»ƒç»†èŠ‚è¯·ç•™æ„æˆ‘ä»¬åç»­å‘å¸ƒçš„è®ºæ–‡ã€‚

## ä½¿ç”¨æ–¹æ³•
* å…‹éš†æœ¬é¡¹ç›®
```bash
cd ~
git clone https://github.com/scutcyr/SoulChat.git
```

* å®‰è£…ä¾èµ–    
éœ€è¦æ³¨æ„çš„æ˜¯torchçš„ç‰ˆæœ¬éœ€è¦æ ¹æ®ä½ çš„æœåŠ¡å™¨å®é™…çš„cudaç‰ˆæœ¬é€‰æ‹©ï¼Œè¯¦æƒ…å‚è€ƒ[pytorchå®‰è£…æŒ‡å—](https://pytorch.org/get-started/previous-versions/)
```bash
cd SoulChat
conda env create -n proactivehealthgpt_py38 --file proactivehealthgpt_py38.yml
conda activate proactivehealthgpt_py38

pip install cpm_kernels
pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116
```

* ã€è¡¥å……ã€‘Windowsä¸‹çš„ç”¨æˆ·æ¨èå‚è€ƒå¦‚ä¸‹æµç¨‹é…ç½®ç¯å¢ƒ
```bash
cd BianQue
conda create -n proactivehealthgpt_py38 python=3.8
conda activate proactivehealthgpt_py38
pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116
pip install -r requirements.txt
pip install rouge_chinese nltk jieba datasets
# ä»¥ä¸‹å®‰è£…ä¸ºäº†è¿è¡Œdemo
pip install streamlit
pip install streamlit_chat
```
* ã€è¡¥å……ã€‘Windowsä¸‹é…ç½®CUDA-11.6ï¼š[ä¸‹è½½å¹¶ä¸”å®‰è£…CUDA-11.6](https://developer.nvidia.com/cuda-11-6-0-download-archive?target_os=Windows&target_arch=x86_64&target_version=11&target_type=exe_local)ã€[ä¸‹è½½cudnn-8.4.0ï¼Œè§£å‹å¹¶ä¸”å¤åˆ¶å…¶ä¸­çš„æ–‡ä»¶åˆ°CUDA-11.6å¯¹åº”çš„è·¯å¾„](https://developer.nvidia.com/compute/cudnn/secure/8.4.0/local_installers/11.6/cudnn-windows-x86_64-8.4.0.27_cuda11.6-archive.zip)ï¼Œå‚è€ƒï¼š[win11ä¸‹åˆ©ç”¨condaè¿›è¡Œpytorchå®‰è£…-cuda11.6-æ³›ç”¨å®‰è£…æ€è·¯](https://blog.csdn.net/qq_34740266/article/details/129137794)

* åœ¨Pythonå½“ä¸­è°ƒç”¨SoulChatæ¨¡å‹    
```python
import torch
from transformers import AutoModel, AutoTokenizer
# GPUè®¾ç½®
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# åŠ è½½æ¨¡å‹ä¸tokenizer
model_name_or_path = 'scutcyr/SoulChat'
model = AutoModel.from_pretrained(model_name_or_path, trust_remote_code=True).half()
model.to(device)
tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)

# å•è½®å¯¹è¯è°ƒç”¨æ¨¡å‹çš„chatå‡½æ•°
user_input = "æˆ‘å¤±æ‹äº†ï¼Œå¥½éš¾å—ï¼"
input_text = "ç”¨æˆ·ï¼š" + user_input + "\nå¿ƒç†å’¨è¯¢å¸ˆï¼š"
response, history = model.chat(tokenizer, query=input_text, history=None, max_length=2048, num_beams=1, do_sample=True, top_p=0.75, temperature=0.95, logits_processor=None)

# å¤šè½®å¯¹è¯è°ƒç”¨æ¨¡å‹çš„chatå‡½æ•°
# æ³¨æ„ï¼šæœ¬é¡¹ç›®ä½¿ç”¨"\nç”¨æˆ·ï¼š"å’Œ"\nå¿ƒç†å’¨è¯¢å¸ˆï¼š"åˆ’åˆ†ä¸åŒè½®æ¬¡çš„å¯¹è¯å†å²
# æ³¨æ„ï¼šuser_historyæ¯”bot_historyçš„é•¿åº¦å¤š1
user_history = ['ä½ å¥½ï¼Œè€å¸ˆ', 'æˆ‘å¥³æœ‹å‹è·Ÿæˆ‘åˆ†æ‰‹äº†ï¼Œæ„Ÿè§‰å¥½éš¾å—']
bot_history = ['ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„ä¸ªäººä¸“å±æ•°å­—è¾…å¯¼å‘˜ç”œå¿ƒè€å¸ˆï¼Œæ¬¢è¿æ‰¾æˆ‘å€¾è¯‰ã€è°ˆå¿ƒï¼ŒæœŸå¾…å¸®åŠ©åˆ°ä½ ï¼']
# æ‹¼æ¥å¯¹è¯å†å²
context = "\n".join([f"ç”¨æˆ·ï¼š{user_history[i]}\nå¿ƒç†å’¨è¯¢å¸ˆï¼š{bot_history[i]}" for i in range(len(bot_history))])
input_text = context + "\nç”¨æˆ·ï¼š" + user_history[-1] + "\nå¿ƒç†å’¨è¯¢å¸ˆï¼š"

response, history = model.chat(tokenizer, query=input_text, history=None, max_length=2048, num_beams=1, do_sample=True, top_p=0.75, temperature=0.95, logits_processor=None)
```


* å¯åŠ¨æœåŠ¡   

æœ¬é¡¹ç›®æä¾›äº†[soulchat_app.py](./soulchat_app.py)ä½œä¸ºSoulChatæ¨¡å‹çš„ä½¿ç”¨ç¤ºä¾‹ï¼Œé€šè¿‡ä»¥ä¸‹å‘½ä»¤å³å¯å¼€å¯æœåŠ¡ï¼Œç„¶åï¼Œé€šè¿‡http://<your_ip>:9026è®¿é—®ã€‚
```bash
streamlit run soulchat_app.py --server.port 9026
```
ç‰¹åˆ«åœ°ï¼Œåœ¨[soulchat_app.py](./soulchat_app.py)å½“ä¸­ï¼Œ
å¯ä»¥ä¿®æ”¹ä»¥ä¸‹ä»£ç æ›´æ¢æŒ‡å®šçš„æ˜¾å¡ï¼š
```python
os.environ['CUDA_VISIBLE_DEVICES'] = '2'
```
**å¯¹äºWindowså•æ˜¾å¡ç”¨æˆ·ï¼Œéœ€è¦ä¿®æ”¹ä¸ºï¼š```os.environ['CUDA_VISIBLE_DEVICES'] = '0'```ï¼Œå¦åˆ™ä¼šæŠ¥é”™ï¼**

å¯ä»¥é€šè¿‡æ›´æ”¹ä»¥ä¸‹ä»£ç æŒ‡å®šæ¨¡å‹è·¯å¾„ä¸ºæœ¬åœ°è·¯å¾„ï¼š
```python
model_name_or_path = 'scutcyr/SoulChat'
```


## ç¤ºä¾‹
* æ ·ä¾‹1ï¼šå¤±æ‹
*
<p align="center">
    <img src="./figure/example_shilian.png" width=600px/>
</p>

* æ ·ä¾‹2ï¼šå®¿èˆå…³ç³»

<p align="center">
    <img src="./figure/example_sushe.png" width=600px/>
</p>

* æ ·ä¾‹3ï¼šæœŸæœ«è€ƒè¯•

<p align="center">
    <img src="./figure/example_kaoshi.png" width=600px/>
</p>

* æ ·ä¾‹4ï¼šç§‘ç ”å‹åŠ›

<p align="center">
    <img src="./figure/example_keyan.png" width=600px/>
</p>

## å£°æ˜
* æœ¬é¡¹ç›®ä½¿ç”¨äº†ChatGLM-6B æ¨¡å‹çš„æƒé‡ï¼Œéœ€è¦éµå¾ªå…¶[MODEL_LICENSE](https://github.com/THUDM/ChatGLM-6B/blob/main/MODEL_LICENSE)ï¼Œå› æ­¤ï¼Œ**æœ¬é¡¹ç›®ä»…å¯ç”¨äºæ‚¨çš„éå•†ä¸šç ”ç©¶ç›®çš„**ã€‚
* æœ¬é¡¹ç›®æä¾›çš„SoulChatæ¨¡å‹è‡´åŠ›äºæå‡å¤§æ¨¡å‹çš„å…±æƒ…å¯¹è¯ä¸å€¾å¬èƒ½åŠ›ï¼Œç„¶è€Œï¼Œæ¨¡å‹çš„è¾“å‡ºæ–‡æœ¬å…·æœ‰ä¸€å®šçš„éšæœºæ€§ï¼Œå½“å…¶ä½œä¸ºä¸€ä¸ªå€¾å¬è€…çš„æ—¶å€™ï¼Œæ˜¯åˆé€‚çš„ï¼Œä½†æ˜¯ä¸å»ºè®®å°†SoulChatæ¨¡å‹çš„è¾“å‡ºæ–‡æœ¬æ›¿ä»£å¿ƒç†åŒ»ç”Ÿç­‰çš„è¯Šæ–­ã€å»ºè®®ã€‚æœ¬é¡¹ç›®ä¸ä¿è¯æ¨¡å‹è¾“å‡ºçš„æ–‡æœ¬å®Œå…¨é€‚åˆäºç”¨æˆ·ï¼Œç”¨æˆ·åœ¨ä½¿ç”¨æœ¬æ¨¡å‹æ—¶éœ€è¦æ‰¿æ‹…å…¶å¸¦æ¥çš„æ‰€æœ‰é£é™©ï¼
* æ‚¨ä¸å¾—å‡ºäºä»»ä½•å•†ä¸šã€å†›äº‹æˆ–éæ³•ç›®çš„ä½¿ç”¨ã€å¤åˆ¶ã€ä¿®æ”¹ã€åˆå¹¶ã€å‘å¸ƒã€åˆ†å‘ã€å¤åˆ¶æˆ–åˆ›å»ºSoulChatæ¨¡å‹çš„å…¨éƒ¨æˆ–éƒ¨åˆ†è¡ç”Ÿä½œå“ã€‚
* æ‚¨ä¸å¾—åˆ©ç”¨SoulChatæ¨¡å‹ä»äº‹ä»»ä½•å±å®³å›½å®¶å®‰å…¨å’Œå›½å®¶ç»Ÿä¸€ã€å±å®³ç¤¾ä¼šå…¬å…±åˆ©ç›Šã€ä¾µçŠ¯äººèº«æƒç›Šçš„è¡Œä¸ºã€‚
* æ‚¨åœ¨ä½¿ç”¨SoulChatæ¨¡å‹æ—¶åº”çŸ¥æ‚‰ï¼Œå…¶ä¸èƒ½æ›¿ä»£åŒ»ç”Ÿã€å¿ƒç†åŒ»ç”Ÿç­‰ä¸“ä¸šäººå£«ï¼Œä¸åº”è¿‡åº¦ä¾èµ–ã€æœä»ã€ç›¸ä¿¡æ¨¡å‹çš„è¾“å‡ºï¼Œä¸èƒ½é•¿æœŸæ²‰è¿·äºä¸SoulChatæ¨¡å‹èŠå¤©ã€‚

## è‡´è°¢
æœ¬é¡¹ç›®ç”±[åå—ç†å·¥å¤§å­¦æœªæ¥æŠ€æœ¯å­¦é™¢](https://www2.scut.edu.cn/ft/main.htm) å¹¿ä¸œçœæ•°å­—å­ªç”Ÿäººé‡ç‚¹å®éªŒå®¤å‘èµ·ï¼Œå¾—åˆ°äº†åå—ç†å·¥å¤§å­¦ä¿¡æ¯ç½‘ç»œå·¥ç¨‹ç ”ç©¶ä¸­å¿ƒã€ç”µå­ä¸ä¿¡æ¯å­¦é™¢ç­‰å­¦é™¢éƒ¨é—¨çš„æ”¯æ’‘ï¼ŒåŒæ—¶è‡´è°¢å¹¿ä¸œçœå¦‡å¹¼ä¿å¥é™¢ã€å¹¿å·å¸‚å¦‡å¥³å„¿ç«¥åŒ»ç–—ä¸­å¿ƒã€ä¸­å±±å¤§å­¦é™„å±ç¬¬ä¸‰åŒ»é™¢ã€åˆè‚¥ç»¼åˆæ€§å›½å®¶ç§‘å­¦ä¸­å¿ƒäººå·¥æ™ºèƒ½ç ”ç©¶é™¢ç­‰åˆä½œå•ä½ã€‚

åŒæ—¶ï¼Œæˆ‘ä»¬æ„Ÿè°¢ä»¥ä¸‹åª’ä½“æˆ–å…¬ä¼—å·å¯¹æœ¬é¡¹ç›®çš„æŠ¥é“ï¼ˆæ’åä¸åˆ†å…ˆåï¼‰ï¼š
* åª’ä½“æŠ¥é“
  [äººæ°‘æ—¥æŠ¥](https://wap.peopleapp.com/article/rmh36174922/rmh36174922)ã€[ä¸­å›½ç½‘](https://hs.china.com.cn/gd/83980.html)ã€[å…‰æ˜ç½‘](https://health.gmw.cn/2023-06/13/content_36628062.htm)ã€[TOMç§‘æŠ€](https://tech.tom.com/202306/4526869977.html)ã€[æœªæ¥ç½‘](http://www.zzfuture.cn/news/956.html)ã€[å¤§ä¼—ç½‘](http://linyi.dzwww.com.3xw.site/xinwen/202306/t20230613_202306135667.htm)ã€[ä¸­å›½å‘å±•æŠ¥é“ç½‘](http://www.chinafzbdw.com/computer/13149.html?1686564408)ã€[ä¸­å›½æ—¥æŠ¥ç½‘](http://energy.chinaduily.com.cn/c/2023/15205.html)ã€[æ–°åèµ„è®¯ç½‘](http://www.xinhuazxun.com/world/21762.html?1686564382)ã€[ä¸­åç½‘](https://life.china.com/2023-06/12/content_215815.html)ã€[ä»Šæ—¥å¤´æ¡](https://www.toutiao.com/article/7243412314223952418/)ã€[æœç‹](https://www.sohu.com/a/684501109_120159010)ã€[è…¾è®¯æ–°é—»](https://page.om.qq.com/page/OhSXIMEUtDtdg0rTi6aAoTbg0)ã€[ç½‘æ˜“æ–°é—»](https://www.163.com/dy/article/I70BJ9U00552UJUX.html)ã€[ä¸­å›½èµ„è®¯ç½‘](http://www.chinazxun.com/world/23252.html?1686564532)ã€[ä¸­å›½ä¼ æ’­ç½‘](http://www.chinachbo.com/a/view/11697.html?1686564509)ã€[ä¸­å›½éƒ½å¸‚æŠ¥é“ç½‘](http://www.zgdsbdw.com/meida/11273.html?1686564485)ã€[ä¸­ååŸå¸‚ç½‘](http://www.zhcsww.com/hot/2023/0612/9609.html?1686564434)

* å…¬ä¼—å·
  [å¹¿ä¸œå®éªŒå®¤å»ºè®¾](https://mp.weixin.qq.com/s/gemlKfLg8c-AtjiV7uTUTQ)ã€[æ™ºèƒ½è¯­éŸ³æ–°é’å¹´](https://mp.weixin.qq.com/s/vBMKXUJoAIywkXY2nY60eA)ã€[æ·±åº¦å­¦ä¹ ä¸NLP](https://mp.weixin.qq.com/s/qSHLT8FbvohZESp-UCah6g)ã€[AINLP](https://mp.weixin.qq.com/s/EX3f9WblLKM8K_nSwhno_g)

## å¼•ç”¨
```bib
      @inproceedings{chen-etal-2023-soulchat,
    title = "{S}oul{C}hat: Improving {LLM}s{'} Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations",
    author = "Chen, Yirong  and
      Xing, Xiaofen  and
      Lin, Jingkai  and
      Zheng, Huimin  and
      Wang, Zhenyu  and
      Liu, Qi  and
      Xu, Xiangmin",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.83",
    pages = "1170--1183",
    abstract = "Large language models (LLMs) have been widely applied in various fields due to their excellent capability for memorizing knowledge and chain of thought (CoT). When these language models are applied in the field of psychological counseling, they often rush to provide universal advice. However, when users seek psychological support, they need to gain empathy, trust, understanding and comfort, rather than just reasonable advice. To this end, we constructed a multi-turn empathetic conversation dataset of more than 2 million samples, in which the input is the multi-turn conversation context, and the target is empathetic responses that cover expressions such as questioning, comfort, recognition, listening, trust, emotional support, etc. Experiments have shown that the empathy ability of LLMs can be significantly enhanced when finetuning by using multi-turn dialogue history and responses that are closer to the expression of a psychological consultant.",
}
}
```

